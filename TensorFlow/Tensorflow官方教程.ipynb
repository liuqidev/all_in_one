{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从示例开始\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np # 和tf配合使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate phony data | 生成假数据\n",
    "# 实际应用应该是面对真实的数据\n",
    "# 100个点，（2x100）\n",
    "x_data = np.float32(np.random.rand(2, 100))\n",
    "y_data = np.dot([0.100, 0.200], x_data)+0.300\n",
    "\n",
    "# 构造线性模型\n",
    "b = tf.Variable(tf.zeros([1])) # tensor of shape 1\n",
    "W = tf.Variable(tf.random_uniform([1, 2], minval=-0.1, maxval=1.0)) # tensor of shape 1x2 whose values are from a uniform distribution \n",
    "# in the range of [minval, maxval)\n",
    "y = tf.matmul(W, x_data)+b\n",
    "\n",
    "# 最小化方差\n",
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化变量\n",
    "# init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动计算图(graph)\n",
    "sess = tf.Session() # 创建会话\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0  W=  [[0.4871506  0.41139394]]  b=  [-0.09778017]\n",
      "Step:  20  W=  [[0.22539519 0.34252512]]  b=  [0.15573283]\n",
      "Step:  40  W=  [[0.14763923 0.26675704]]  b=  [0.23892412]\n",
      "Step:  60  W=  [[0.11975352 0.22945689]]  b=  [0.2737922]\n",
      "Step:  80  W=  [[0.10842387 0.21279107]]  b=  [0.2887098]\n",
      "Step:  100  W=  [[0.10362242 0.20552918]]  b=  [0.2951307]\n",
      "Step:  120  W=  [[0.10156146 0.20238699]]  b=  [0.29789925]\n",
      "Step:  140  W=  [[0.10067356 0.2010301 ]]  b=  [0.2990936]\n",
      "Step:  160  W=  [[0.10029061 0.20044449]]  b=  [0.29960892]\n",
      "Step:  180  W=  [[0.10012538 0.20019177]]  b=  [0.29983127]\n",
      "Step:  200  W=  [[0.10005409 0.20008272]]  b=  [0.2999272]\n",
      "ha?\n"
     ]
    }
   ],
   "source": [
    "# 拟合平面\n",
    "for step in range(0, 201):\n",
    "    sess.run(train)\n",
    "    if step%20==0:\n",
    "        print(\"Step: \", step, \" W= \",sess.run(W), \" b= \", sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关闭会话\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST机器学习入门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://yann.lecun.com/exdb/mnist/  to download mnist dataset\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py\n",
    "# to read dataset\n",
    "from load_mnist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "minst_dir = \"MNIST_data/\"\n",
    "mnist = input_data.read_data_sets(minst_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载下来的数据集被分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）.\n",
    "\n",
    "每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。我们把这些图片设为“xs”，把这些标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels.\n",
    "\n",
    "每一张图片包含28像素X28像素。我们可以用一个数字数组来表示这张图片：\n",
    "![](http://www.tensorfly.cn/tfdoc/images/MNIST-Matrix.png)\n",
    "\n",
    "我们把这个数组展开成一个向量，长度是 28x28 = 784。如何展开这个数组（数字间的顺序）不重要，只要保持各个图片采用相同的方式展开。从这个角度来看，MNIST数据集的图片就是在784维向量空间里面的点, 并且拥有比较复杂的结构 (提醒: 此类数据的可视化是计算密集型的)。\n",
    "\n",
    "在MNIST训练数据集中，mnist.train.images 是一个形状为 `[60000, 784] `的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。\n",
    "![](http://www.tensorfly.cn/tfdoc/images/mnist-train-xs.png)\n",
    "\n",
    "相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。为了用于这个教程，我们使标签数据是\"one-hot vectors\"。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成(`[1,0,0,0,0,0,0,0,0,0,0])`。因此， mnist.train.labels 是一个` [60000, 10] `的数字矩阵。\n",
    "![](http://www.tensorfly.cn/tfdoc/images/mnist-train-ys.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x represent the input\n",
    "# None means number of images is adaptable\n",
    "# a 28x28 image is flatten to a vector of 784\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax regression\n",
    "关于Softmax可以阅读[这篇](http://www.tensorfly.cn/tfdoc/tutorials/mnist_beginners.html)或者[这篇](http://neuralnetworksanddeeplearning.com/chap3.html).\n",
    "\n",
    "![](http://www.tensorfly.cn/tfdoc/images/mnist6.png)\n",
    "\n",
    "整个回归模型：\n",
    "![](http://www.tensorfly.cn/tfdoc/images/softmax-regression-scalargraph.png)\n",
    "![](http://www.tensorfly.cn/tfdoc/images/mnist7.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "使用交叉熵损失函数，更多介绍看[这篇](https://colah.github.io/posts/2015-09-Visual-Information/).\n",
    "![](http://www.tensorfly.cn/tfdoc/images/mnist10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "# 注意，这里的交叉熵不仅仅用来衡量单一的一对预测和真实值，而是所有100幅图片的交叉熵的总和\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent and backprapagation\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多优化算法点击[这里](http://www.tensorfly.cn/tfdoc/api_docs/python/train.html#optimizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init graph\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        feed_dict ={x: batch_xs, y_:batch_ys}\n",
    "        sess.run(train_step, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估我们的模型\n",
    "\n",
    "tf.argmax 是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如tf.argmax(y,1)返回的是模型对于任一输入x预测到的标签值，而 tf.argmax(y_,1) 代表正确的标签，我们可以用 tf.equal 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  train acc:  0.48\n",
      "100  train acc:  0.94\n",
      "200  train acc:  0.96\n",
      "300  train acc:  0.93\n",
      "400  train acc:  0.93\n",
      "500  train acc:  0.89\n",
      "600  train acc:  0.96\n",
      "700  train acc:  0.94\n",
      "800  train acc:  0.94\n",
      "900  train acc:  0.95\n",
      "1000  train acc:  0.98\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        feed_dict ={x: batch_xs, y_:batch_ys}\n",
    "        sess.run(train_step, feed_dict)\n",
    "        if step%100==0:\n",
    "            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print(step, \" train acc: \", sess.run(accuracy, feed_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9138\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        feed_dict ={x: batch_xs, y_:batch_ys}\n",
    "        sess.run(train_step, feed_dict)\n",
    "#         if step%100==0:\n",
    "#             correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "#             accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#             print(step, \" train acc: \", sess.run(accuracy, feed_dict))\n",
    "#   # for test set\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Test acc:\", sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多内容[https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本文首先通过一个完整的线性回归的例子，展示了TensorFlow的基本使用，首先构造计算图graph，其中包含诸如`Variable`、`placeholder`等节点，以及节点之间的数学运算如矩阵乘法；接着对计算图初始化，`tf.global_variables_initializer()`，其中TensorFlow中很重要的就是回话session机制，通过会话来运行计算图；随后，通过会话进行训练，拟合并德大检测结果。\n",
    "\n",
    "其次，使用TensorFlow完成了基于MNIST数据集，进行手写体识别的任务，并在测试集上实现了91%的正确率。\n",
    "其完整过程，首先是准备数据，下载的数据被分为训练数据和测试数据。每种数据的基本单元都包含两部分，一部分是手写体图片，统一规格28x28，另一部分是对应的标记，来指出对应的数字，将原始图片展开向量表示，标记采用one-hot表示；\n",
    "接着，构建softmax回归模型。使用梯度下降算法进行反向传播，最小化交叉熵损失进行训练。\n",
    "最后，在测试机上测试，得到实验正确率指标，可以达到91%以上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
